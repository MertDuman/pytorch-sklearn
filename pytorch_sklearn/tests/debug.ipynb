{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_sklearn.neural_network.neural_network import NeuralNetwork\n",
    "from pytorch_sklearn.neural_network.generative_network import CycleGAN\n",
    "from pytorch_sklearn.callbacks.predefined import Verbose, History, EarlyStopping\n",
    "from pytorch_sklearn.utils.progress_bar import print_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return self.conv3(x)\n",
    "    \n",
    "class SimpleDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleDiscriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=4)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=4)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=3, padding=1)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.maxpool1(self.conv1(x)))\n",
    "        x = F.relu(self.maxpool2(self.conv2(x)))\n",
    "        x = self.maxpool3(self.conv3(x))\n",
    "        return x.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleDiscriminator()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "crit = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(10, 3, 32, 32)\n",
    "y = torch.randn(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork(model, optim, crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [====================] - train_loss: 0.682 - train_l1loss: 0.678 - train_l2loss: 0.682 - Time: 0.45 - ETA: 0.00\n",
      "Epoch 2/50\n",
      "1/1 [====================] - train_loss: 0.535 - train_l1loss: 0.574 - train_l2loss: 0.535 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 3/50\n",
      "1/1 [====================] - train_loss: 0.467 - train_l1loss: 0.514 - train_l2loss: 0.467 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 4/50\n",
      "1/1 [====================] - train_loss: 0.474 - train_l1loss: 0.522 - train_l2loss: 0.474 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 5/50\n",
      "1/1 [====================] - train_loss: 0.467 - train_l1loss: 0.527 - train_l2loss: 0.467 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 6/50\n",
      "1/1 [====================] - train_loss: 0.429 - train_l1loss: 0.498 - train_l2loss: 0.429 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 7/50\n",
      "1/1 [====================] - train_loss: 0.389 - train_l1loss: 0.462 - train_l2loss: 0.389 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 8/50\n",
      "1/1 [====================] - train_loss: 0.365 - train_l1loss: 0.460 - train_l2loss: 0.365 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 9/50\n",
      "1/1 [====================] - train_loss: 0.353 - train_l1loss: 0.463 - train_l2loss: 0.353 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 10/50\n",
      "1/1 [====================] - train_loss: 0.341 - train_l1loss: 0.458 - train_l2loss: 0.341 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 11/50\n",
      "1/1 [====================] - train_loss: 0.321 - train_l1loss: 0.443 - train_l2loss: 0.321 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 12/50\n",
      "1/1 [====================] - train_loss: 0.298 - train_l1loss: 0.422 - train_l2loss: 0.298 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 13/50\n",
      "1/1 [====================] - train_loss: 0.278 - train_l1loss: 0.399 - train_l2loss: 0.278 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 14/50\n",
      "1/1 [====================] - train_loss: 0.263 - train_l1loss: 0.380 - train_l2loss: 0.263 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 15/50\n",
      "1/1 [====================] - train_loss: 0.254 - train_l1loss: 0.369 - train_l2loss: 0.254 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 16/50\n",
      "1/1 [====================] - train_loss: 0.232 - train_l1loss: 0.354 - train_l2loss: 0.232 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 17/50\n",
      "1/1 [====================] - train_loss: 0.214 - train_l1loss: 0.342 - train_l2loss: 0.214 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 18/50\n",
      "1/1 [====================] - train_loss: 0.198 - train_l1loss: 0.335 - train_l2loss: 0.198 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 19/50\n",
      "1/1 [====================] - train_loss: 0.185 - train_l1loss: 0.331 - train_l2loss: 0.185 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 20/50\n",
      "1/1 [====================] - train_loss: 0.174 - train_l1loss: 0.325 - train_l2loss: 0.174 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 21/50\n",
      "1/1 [====================] - train_loss: 0.162 - train_l1loss: 0.316 - train_l2loss: 0.162 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 22/50\n",
      "1/1 [====================] - train_loss: 0.149 - train_l1loss: 0.302 - train_l2loss: 0.149 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 23/50\n",
      "1/1 [====================] - train_loss: 0.135 - train_l1loss: 0.284 - train_l2loss: 0.135 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 24/50\n",
      "1/1 [====================] - train_loss: 0.122 - train_l1loss: 0.263 - train_l2loss: 0.122 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 25/50\n",
      "1/1 [====================] - train_loss: 0.112 - train_l1loss: 0.244 - train_l2loss: 0.112 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 26/50\n",
      "1/1 [====================] - train_loss: 0.101 - train_l1loss: 0.231 - train_l2loss: 0.101 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 27/50\n",
      "1/1 [====================] - train_loss: 0.089 - train_l1loss: 0.217 - train_l2loss: 0.089 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 28/50\n",
      "1/1 [====================] - train_loss: 0.077 - train_l1loss: 0.208 - train_l2loss: 0.077 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 29/50\n",
      "1/1 [====================] - train_loss: 0.067 - train_l1loss: 0.201 - train_l2loss: 0.067 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 30/50\n",
      "1/1 [====================] - train_loss: 0.059 - train_l1loss: 0.191 - train_l2loss: 0.059 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 31/50\n",
      "1/1 [====================] - train_loss: 0.052 - train_l1loss: 0.179 - train_l2loss: 0.052 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 32/50\n",
      "1/1 [====================] - train_loss: 0.043 - train_l1loss: 0.162 - train_l2loss: 0.043 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 33/50\n",
      "1/1 [====================] - train_loss: 0.034 - train_l1loss: 0.144 - train_l2loss: 0.034 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 34/50\n",
      "1/1 [====================] - train_loss: 0.029 - train_l1loss: 0.127 - train_l2loss: 0.029 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 35/50\n",
      "1/1 [====================] - train_loss: 0.023 - train_l1loss: 0.110 - train_l2loss: 0.023 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 36/50\n",
      "1/1 [====================] - train_loss: 0.019 - train_l1loss: 0.097 - train_l2loss: 0.019 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 37/50\n",
      "1/1 [====================] - train_loss: 0.014 - train_l1loss: 0.086 - train_l2loss: 0.014 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 38/50\n",
      "1/1 [====================] - train_loss: 0.011 - train_l1loss: 0.075 - train_l2loss: 0.011 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 39/50\n",
      "1/1 [====================] - train_loss: 0.008 - train_l1loss: 0.064 - train_l2loss: 0.008 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 40/50\n",
      "1/1 [====================] - train_loss: 0.005 - train_l1loss: 0.053 - train_l2loss: 0.005 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 41/50\n",
      "1/1 [====================] - train_loss: 0.003 - train_l1loss: 0.040 - train_l2loss: 0.003 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 42/50\n",
      "1/1 [====================] - train_loss: 0.002 - train_l1loss: 0.027 - train_l2loss: 0.002 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 43/50\n",
      "1/1 [====================] - train_loss: 0.001 - train_l1loss: 0.024 - train_l2loss: 0.001 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 44/50\n",
      "1/1 [====================] - train_loss: 0.000 - train_l1loss: 0.017 - train_l2loss: 0.000 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 45/50\n",
      "1/1 [====================] - train_loss: 0.000 - train_l1loss: 0.012 - train_l2loss: 0.000 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 46/50\n",
      "1/1 [====================] - train_loss: 0.000 - train_l1loss: 0.016 - train_l2loss: 0.000 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 47/50\n",
      "1/1 [====================] - train_loss: 0.001 - train_l1loss: 0.022 - train_l2loss: 0.001 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 48/50\n",
      "1/1 [====================] - train_loss: 0.001 - train_l1loss: 0.026 - train_l2loss: 0.001 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 49/50\n",
      "1/1 [====================] - train_loss: 0.001 - train_l1loss: 0.031 - train_l2loss: 0.001 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 50/50\n",
      "1/1 [====================] - train_loss: 0.002 - train_l1loss: 0.034 - train_l2loss: 0.002 - Time: 0.01 - ETA: 0.00\n"
     ]
    }
   ],
   "source": [
    "net.fit(\n",
    "    train_X=X,\n",
    "    train_y=y,\n",
    "    max_epochs=50,\n",
    "    callbacks=[Verbose(notebook=True)],\n",
    "    metrics={'l1loss': nn.L1Loss(), 'l2loss': nn.MSELoss()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4190],\n",
       "        [ 0.7362],\n",
       "        [-1.9413],\n",
       "        [ 0.6315],\n",
       "        [-0.8139],\n",
       "        [-0.5805],\n",
       "        [-0.5343],\n",
       "        [-0.9665],\n",
       "        [-0.0397],\n",
       "        [-0.1518]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.A = torch.randn(10, 3, 32, 32) * .1\n",
    "        self.B = torch.randn(10, 3, 32, 32) * .8\n",
    "\n",
    "    def __len__(self):\n",
    "        return 10\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.A[index], self.B[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STDMetric:\n",
    "    def __init__(self):\n",
    "        self.stdA = []\n",
    "        self.stdB = []\n",
    "        self.stdA2B = []\n",
    "        self.stdB2A = []\n",
    "\n",
    "    def __call__(self, batch_out, batch_y):\n",
    "        A2B, B2A = batch_out\n",
    "        A, B = batch_y\n",
    "        self.stdA.append(A.std().item())\n",
    "        self.stdB.append(B.std().item())\n",
    "        self.stdA2B.append(A2B.std().item())\n",
    "        self.stdB2A.append(B2A.std().item())\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_A = SimpleCNN()\n",
    "G_B = SimpleCNN()\n",
    "D_A = SimpleDiscriminator()\n",
    "D_B = SimpleDiscriminator()\n",
    "\n",
    "G_optim = torch.optim.Adam(list(G_A.parameters()) + list(G_B.parameters()), lr=0.001)\n",
    "D_optim = torch.optim.Adam(list(D_A.parameters()) + list(D_B.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan = CycleGAN(G_A, G_B, D_A, D_B, G_optim, D_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_ds = CycleGANDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_metric = STDMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/700\n",
      "1/1 [====================] - train_loss: 4.695 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 602/700\n",
      "1/1 [====================] - train_loss: 4.710 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 603/700\n",
      "1/1 [====================] - train_loss: 4.727 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 604/700\n",
      "1/1 [====================] - train_loss: 4.738 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 605/700\n",
      "1/1 [====================] - train_loss: 4.717 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 606/700\n",
      "1/1 [====================] - train_loss: 4.706 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 607/700\n",
      "1/1 [====================] - train_loss: 4.706 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 608/700\n",
      "1/1 [====================] - train_loss: 4.708 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 609/700\n",
      "1/1 [====================] - train_loss: 4.712 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 610/700\n",
      "1/1 [====================] - train_loss: 4.725 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 611/700\n",
      "1/1 [====================] - train_loss: 4.734 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 612/700\n",
      "1/1 [====================] - train_loss: 4.736 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 613/700\n",
      "1/1 [====================] - train_loss: 4.732 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 614/700\n",
      "1/1 [====================] - train_loss: 4.736 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 615/700\n",
      "1/1 [====================] - train_loss: 4.739 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 616/700\n",
      "1/1 [====================] - train_loss: 4.747 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 617/700\n",
      "1/1 [====================] - train_loss: 4.753 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 618/700\n",
      "1/1 [====================] - train_loss: 4.753 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 619/700\n",
      "1/1 [====================] - train_loss: 4.758 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 620/700\n",
      "1/1 [====================] - train_loss: 4.774 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 621/700\n",
      "1/1 [====================] - train_loss: 4.773 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 622/700\n",
      "1/1 [====================] - train_loss: 4.768 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 623/700\n",
      "1/1 [====================] - train_loss: 4.780 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 624/700\n",
      "1/1 [====================] - train_loss: 4.791 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 625/700\n",
      "1/1 [====================] - train_loss: 4.791 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 626/700\n",
      "1/1 [====================] - train_loss: 4.785 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 627/700\n",
      "1/1 [====================] - train_loss: 4.800 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 628/700\n",
      "1/1 [====================] - train_loss: 4.803 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 629/700\n",
      "1/1 [====================] - train_loss: 4.803 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 630/700\n",
      "1/1 [====================] - train_loss: 4.800 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 631/700\n",
      "1/1 [====================] - train_loss: 4.804 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 632/700\n",
      "1/1 [====================] - train_loss: 4.809 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 633/700\n",
      "1/1 [====================] - train_loss: 4.822 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 634/700\n",
      "1/1 [====================] - train_loss: 4.825 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 635/700\n",
      "1/1 [====================] - train_loss: 4.826 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 636/700\n",
      "1/1 [====================] - train_loss: 4.835 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 637/700\n",
      "1/1 [====================] - train_loss: 4.836 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 638/700\n",
      "1/1 [====================] - train_loss: 4.830 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 639/700\n",
      "1/1 [====================] - train_loss: 4.842 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 640/700\n",
      "1/1 [====================] - train_loss: 4.857 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 641/700\n",
      "1/1 [====================] - train_loss: 4.861 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 642/700\n",
      "1/1 [====================] - train_loss: 4.864 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 643/700\n",
      "1/1 [====================] - train_loss: 4.871 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 644/700\n",
      "1/1 [====================] - train_loss: 4.870 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 645/700\n",
      "1/1 [====================] - train_loss: 4.882 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 646/700\n",
      "1/1 [====================] - train_loss: 4.896 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 647/700\n",
      "1/1 [====================] - train_loss: 4.887 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 648/700\n",
      "1/1 [====================] - train_loss: 4.898 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 649/700\n",
      "1/1 [====================] - train_loss: 4.911 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 650/700\n",
      "1/1 [====================] - train_loss: 4.908 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 651/700\n",
      "1/1 [====================] - train_loss: 4.912 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 652/700\n",
      "1/1 [====================] - train_loss: 4.924 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 653/700\n",
      "1/1 [====================] - train_loss: 4.925 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 654/700\n",
      "1/1 [====================] - train_loss: 4.940 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 655/700\n",
      "1/1 [====================] - train_loss: 4.946 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 656/700\n",
      "1/1 [====================] - train_loss: 4.935 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 657/700\n",
      "1/1 [====================] - train_loss: 4.956 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 658/700\n",
      "1/1 [====================] - train_loss: 4.974 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 659/700\n",
      "1/1 [====================] - train_loss: 4.946 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 660/700\n",
      "1/1 [====================] - train_loss: 4.971 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 661/700\n",
      "1/1 [====================] - train_loss: 5.004 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 662/700\n",
      "1/1 [====================] - train_loss: 4.975 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 663/700\n",
      "1/1 [====================] - train_loss: 4.985 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 664/700\n",
      "1/1 [====================] - train_loss: 5.010 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 665/700\n",
      "1/1 [====================] - train_loss: 5.013 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 666/700\n",
      "1/1 [====================] - train_loss: 5.026 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 667/700\n",
      "1/1 [====================] - train_loss: 5.027 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 668/700\n",
      "1/1 [====================] - train_loss: 5.022 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 669/700\n",
      "1/1 [====================] - train_loss: 5.052 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 670/700\n",
      "1/1 [====================] - train_loss: 5.083 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 671/700\n",
      "1/1 [====================] - train_loss: 5.049 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 672/700\n",
      "1/1 [====================] - train_loss: 5.039 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 673/700\n",
      "1/1 [====================] - train_loss: 5.077 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 674/700\n",
      "1/1 [====================] - train_loss: 5.092 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 675/700\n",
      "1/1 [====================] - train_loss: 5.082 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 676/700\n",
      "1/1 [====================] - train_loss: 5.080 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 677/700\n",
      "1/1 [====================] - train_loss: 5.088 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 678/700\n",
      "1/1 [====================] - train_loss: 5.088 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 679/700\n",
      "1/1 [====================] - train_loss: 5.114 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 680/700\n",
      "1/1 [====================] - train_loss: 5.109 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 681/700\n",
      "1/1 [====================] - train_loss: 5.107 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 682/700\n",
      "1/1 [====================] - train_loss: 5.145 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 683/700\n",
      "1/1 [====================] - train_loss: 5.148 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 684/700\n",
      "1/1 [====================] - train_loss: 5.128 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 685/700\n",
      "1/1 [====================] - train_loss: 5.152 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 686/700\n",
      "1/1 [====================] - train_loss: 5.175 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 687/700\n",
      "1/1 [====================] - train_loss: 5.164 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 688/700\n",
      "1/1 [====================] - train_loss: 5.164 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 689/700\n",
      "1/1 [====================] - train_loss: 5.185 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 690/700\n",
      "1/1 [====================] - train_loss: 5.187 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 691/700\n",
      "1/1 [====================] - train_loss: 5.195 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 692/700\n",
      "1/1 [====================] - train_loss: 5.212 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 693/700\n",
      "1/1 [====================] - train_loss: 5.209 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 694/700\n",
      "1/1 [====================] - train_loss: 5.239 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 695/700\n",
      "1/1 [====================] - train_loss: 5.250 - train_std: 0.000 - Time: 0.03 - ETA: 0.00\n",
      "Epoch 696/700\n",
      "1/1 [====================] - train_loss: 5.245 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 697/700\n",
      "1/1 [====================] - train_loss: 5.263 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 698/700\n",
      "1/1 [====================] - train_loss: 5.271 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 699/700\n",
      "1/1 [====================] - train_loss: 5.268 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n",
      "Epoch 700/700\n",
      "1/1 [====================] - train_loss: 5.286 - train_std: 0.000 - Time: 0.02 - ETA: 0.00\n"
     ]
    }
   ],
   "source": [
    "cycle_gan.fit(\n",
    "    train_X=cycle_gan_ds,\n",
    "    max_epochs=100,\n",
    "    callbacks=[Verbose(notebook=True)],\n",
    "    metrics={'std': std_metric},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(std_metric.stdA, label='A')\n",
    "plt.plot(std_metric.stdB, label='B')\n",
    "plt.plot(std_metric.stdA2B, label='A2B')\n",
    "plt.plot(std_metric.stdB2A, label='B2A')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
