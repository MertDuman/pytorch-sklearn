{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_sklearn.neural_network.neural_network_copy import NeuralNetwork as NeuralNetworkDev\n",
    "from pytorch_sklearn.neural_network.neural_network import NeuralNetwork\n",
    "from pytorch_sklearn.callbacks.predefined import Verbose, History, EarlyStopping\n",
    "from pytorch_sklearn.utils.progress_bar import print_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return self.conv3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "crit = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(10, 3, 32, 32)\n",
    "y = torch.randn(10, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork(model, optim, crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1/1 [====================] - train_loss: 0.938 - train_l1loss: 0.774 - train_l2loss: 0.938 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 52/100\n",
      "1/1 [====================] - train_loss: 0.935 - train_l1loss: 0.773 - train_l2loss: 0.935 - Time: 0.01 - ETA: 0.00\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 53/100\n",
      "1/1 [====================] - train_loss: 0.933 - train_l1loss: 0.772 - train_l2loss: 0.933 - Time: 0.06 - ETA: 0.00\n",
      "Epoch 54/100\n",
      "1/1 [====================] - train_loss: 0.931 - train_l1loss: 0.771 - train_l2loss: 0.931 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 55/100\n",
      "1/1 [====================] - train_loss: 0.929 - train_l1loss: 0.770 - train_l2loss: 0.929 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 56/100\n",
      "1/1 [====================] - train_loss: 0.927 - train_l1loss: 0.769 - train_l2loss: 0.927 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 57/100\n",
      "1/1 [====================] - train_loss: 0.924 - train_l1loss: 0.768 - train_l2loss: 0.924 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 58/100\n",
      "1/1 [====================] - train_loss: 0.922 - train_l1loss: 0.767 - train_l2loss: 0.922 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 59/100\n",
      "1/1 [====================] - train_loss: 0.920 - train_l1loss: 0.766 - train_l2loss: 0.920 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 60/100\n",
      "1/1 [====================] - train_loss: 0.917 - train_l1loss: 0.765 - train_l2loss: 0.917 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 61/100\n",
      "1/1 [====================] - train_loss: 0.915 - train_l1loss: 0.764 - train_l2loss: 0.915 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 62/100\n",
      "1/1 [====================] - train_loss: 0.913 - train_l1loss: 0.763 - train_l2loss: 0.913 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 63/100\n",
      "1/1 [====================] - train_loss: 0.910 - train_l1loss: 0.762 - train_l2loss: 0.910 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 64/100\n",
      "1/1 [====================] - train_loss: 0.907 - train_l1loss: 0.761 - train_l2loss: 0.907 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 65/100\n",
      "1/1 [====================] - train_loss: 0.905 - train_l1loss: 0.760 - train_l2loss: 0.905 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 66/100\n",
      "1/1 [====================] - train_loss: 0.902 - train_l1loss: 0.759 - train_l2loss: 0.902 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 67/100\n",
      "1/1 [====================] - train_loss: 0.900 - train_l1loss: 0.758 - train_l2loss: 0.900 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 68/100\n",
      "1/1 [====================] - train_loss: 0.897 - train_l1loss: 0.757 - train_l2loss: 0.897 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 69/100\n",
      "1/1 [====================] - train_loss: 0.894 - train_l1loss: 0.756 - train_l2loss: 0.894 - Time: 0.01 - ETA: 0.00\n",
      "Epoch 70/100\n",
      "1/1 [====================] - train_loss: 0.891 - train_l1loss: 0.754 - train_l2loss: 0.891 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 71/100\n",
      "1/1 [====================] - train_loss: 0.889 - train_l1loss: 0.753 - train_l2loss: 0.889 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 72/100\n",
      "1/1 [====================] - train_loss: 0.886 - train_l1loss: 0.752 - train_l2loss: 0.886 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 73/100\n",
      "1/1 [====================] - train_loss: 0.883 - train_l1loss: 0.751 - train_l2loss: 0.883 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 74/100\n",
      "1/1 [====================] - train_loss: 0.880 - train_l1loss: 0.750 - train_l2loss: 0.880 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 75/100\n",
      "1/1 [====================] - train_loss: 0.877 - train_l1loss: 0.748 - train_l2loss: 0.877 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 76/100\n",
      "1/1 [====================] - train_loss: 0.874 - train_l1loss: 0.747 - train_l2loss: 0.874 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 77/100\n",
      "1/1 [====================] - train_loss: 0.872 - train_l1loss: 0.746 - train_l2loss: 0.872 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 78/100\n",
      "1/1 [====================] - train_loss: 0.869 - train_l1loss: 0.745 - train_l2loss: 0.869 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 79/100\n",
      "1/1 [====================] - train_loss: 0.866 - train_l1loss: 0.743 - train_l2loss: 0.866 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 80/100\n",
      "1/1 [====================] - train_loss: 0.863 - train_l1loss: 0.742 - train_l2loss: 0.863 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 81/100\n",
      "1/1 [====================] - train_loss: 0.860 - train_l1loss: 0.741 - train_l2loss: 0.860 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 82/100\n",
      "1/1 [====================] - train_loss: 0.857 - train_l1loss: 0.739 - train_l2loss: 0.857 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 83/100\n",
      "1/1 [====================] - train_loss: 0.854 - train_l1loss: 0.738 - train_l2loss: 0.854 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 84/100\n",
      "1/1 [====================] - train_loss: 0.852 - train_l1loss: 0.737 - train_l2loss: 0.852 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 85/100\n",
      "1/1 [====================] - train_loss: 0.849 - train_l1loss: 0.736 - train_l2loss: 0.849 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 86/100\n",
      "1/1 [====================] - train_loss: 0.846 - train_l1loss: 0.735 - train_l2loss: 0.846 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 87/100\n",
      "1/1 [====================] - train_loss: 0.843 - train_l1loss: 0.734 - train_l2loss: 0.843 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 88/100\n",
      "1/1 [====================] - train_loss: 0.841 - train_l1loss: 0.733 - train_l2loss: 0.841 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 89/100\n",
      "1/1 [====================] - train_loss: 0.838 - train_l1loss: 0.731 - train_l2loss: 0.838 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 90/100\n",
      "1/1 [====================] - train_loss: 0.836 - train_l1loss: 0.730 - train_l2loss: 0.836 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 91/100\n",
      "1/1 [====================] - train_loss: 0.834 - train_l1loss: 0.729 - train_l2loss: 0.834 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 92/100\n",
      "1/1 [====================] - train_loss: 0.831 - train_l1loss: 0.728 - train_l2loss: 0.831 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 93/100\n",
      "1/1 [====================] - train_loss: 0.828 - train_l1loss: 0.727 - train_l2loss: 0.828 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 94/100\n",
      "1/1 [====================] - train_loss: 0.826 - train_l1loss: 0.726 - train_l2loss: 0.826 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 95/100\n",
      "1/1 [====================] - train_loss: 0.824 - train_l1loss: 0.725 - train_l2loss: 0.824 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 96/100\n",
      "1/1 [====================] - train_loss: 0.821 - train_l1loss: 0.724 - train_l2loss: 0.821 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 97/100\n",
      "1/1 [====================] - train_loss: 0.819 - train_l1loss: 0.723 - train_l2loss: 0.819 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 98/100\n",
      "1/1 [====================] - train_loss: 0.817 - train_l1loss: 0.722 - train_l2loss: 0.817 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 99/100\n",
      "1/1 [====================] - train_loss: 0.814 - train_l1loss: 0.721 - train_l2loss: 0.814 - Time: 0.00 - ETA: 0.00\n",
      "Epoch 100/100\n",
      "1/1 [====================] - train_loss: 0.812 - train_l1loss: 0.720 - train_l2loss: 0.812 - Time: 0.00 - ETA: 0.00\n"
     ]
    }
   ],
   "source": [
    "net.fit(\n",
    "    train_X=X,\n",
    "    train_y=y,\n",
    "    max_epochs=50,\n",
    "    callbacks=[Verbose(notebook=True)],\n",
    "    metrics={'l1loss': nn.L1Loss(), 'l2loss': nn.MSELoss()},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
